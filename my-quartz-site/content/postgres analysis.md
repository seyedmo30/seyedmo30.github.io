
# Data Analysis in PostgreSQL

برای آنالیز داده‌ها، می‌توان از کوئری‌های پیچیده استفاده کرد.  
نکته‌ها:  

- این کوئری‌ها معمولاً ایندکس نشده‌اند.
- هدف استفاده توسط **ادمین‌ها** یا در موارد بسیار نادر توسط کاربران است.
- داده‌ها فقط از دیتابیس گرفته می‌شوند و نباید در کد تغییر داده شوند.

شاید PostgreSQL بهترین ابزار آنالیز نباشد، اما با تکنیک‌ها و فانکشن‌های مختلف می‌توان تحلیل‌های مفیدی انجام داد.

### تکنیک‌ها و فانکشن‌ها

#### 1. کار با رشته‌ها
- `lower()`, `upper()`, `trim()`, `substring()`

#### 2. کار با تاریخ و زمان
- `to_char()`, `trunc()`  
- توجه: نیاز به راه‌حل مناسب برای تاریخ شمسی است.

#### 3. مپ کردن مقادیر
- `CASE` برای تبدیل عدد یا مقدار به رشته‌ی مشخص.

#### 4. گرد کردن اعداد
- `round()`, `floor()`, `ceil()`

#### 5. تبدیل نوع داده
- `CAST()` برای تبدیل عدد به رشته یا تاریخ به عدد

#### 6. مدیریت مقادیر NULL
- `COALESCE()` برای جایگزینی مقدار نال با مقدار دلخواه.

#### 7. تحلیل داده‌ها با ستون مشترک
- به جای `GROUP BY` می‌توان از **Window Functions** استفاده کرد.  
- مثال: برای یوزرها در یک شهر، رتبه‌بندی حقوق آن‌ها بدون ترکیب در یک سطر، اما با ردیف‌بندی دقیق:




```sql
SELECT
    city,
    user_id,
    salary,
    RANK() OVER(PARTITION BY city ORDER BY salary DESC) AS city_rank
FROM users;
```


### ETL / ELT

ETL = Extract → Transform → Load

یعنی داده از منبع گرفته می‌شود → تبدیل می‌شود → وارد warehouse می‌شود.

ELT = Extract → Load → Transform

داده خام لود می‌شود و تبدیل در دیتابیس‌هایی مثل BigQuery/Snowflake انجام می‌شود.

### CDC (Change Data Capture)

راهکار استخراج فقط تغییرات روی دیتابیس، نه کل جدول.

+ مبتنی بر WAL (مثلاً PostgreSQL logical decoding)

+ مبتنی بر Trigger

+ مبتنی بر Query-based polling

### چرا warehouseها معمولاً denormalized هستند؟

+ Star Schema 
 
 اسکیما هایی که دینورمالایز هستند یعنی حجم بیشتر میگیرند ولی جویین ندارن

+ Snowflake Schema

 اسکیما نورمالایز هستن جویین ها خیلی زیاد و برای آنالیزور  خیلی سخت اما فضا کمتر می خواد و کانسیستنسی بهتر

 


در OLTP (سیستم‌های عملیاتی مثل بانک، فروشگاه، سفارشات) داده‌ها معمولاً Normalized هستند:

کاهش redundancy

جلوگیری از anomalyها

تمرکز بر write performance و consistency

اما در Data Warehouse (DW) هدف کاملاً برعکس است:

 سرعت Query بالا - (Joinهای زیاد کند هستند → پس جدول‌ها تا جای ممکن ساده و یکپارچه نگه داشته می‌شوند).

 تحلیل‌گر بدون فکر کردن به ۱۲ تا join پشت‌سرهم
